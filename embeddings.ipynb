{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd11fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4381dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentence \n",
    "sentence=['the glass of milk', 'the glass of juice ', 'the cup of tea', 'I am a good boy', 'understand the meaning of words','your videos are good']  ## this is the(corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9852b3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice ',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4cc4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Define the vocabulary size \n",
    "voc_size =10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b29a80",
   "metadata": {},
   "source": [
    "This one_hot is not exactly classical one-hot encoding, but rather a hashing trick:\n",
    "\n",
    "It converts words in a sentence into integers between 1 and voc_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03bc7cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8275, 8122, 2833, 6354],\n",
       " [8275, 8122, 2833, 1983],\n",
       " [8275, 6656, 2833, 8193],\n",
       " [1457, 8808, 3496, 7470, 7507],\n",
       " [8789, 8275, 7286, 2833, 2067],\n",
       " [8120, 591, 1297, 7470]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## One-hot Representation,   \n",
    "one_hot_repre = [one_hot(words,voc_size) for words in sentence]\n",
    "one_hot_repre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e73a1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the glass of milk\n",
      "\n",
      "the glass of juice \n",
      "\n",
      "the cup of tea\n",
      "\n",
      "I am a good boy\n",
      "\n",
      "understand the meaning of words\n",
      "\n",
      "your videos are good\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for words in sentence:\n",
    "    print(f\"{words}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe210ea",
   "metadata": {},
   "source": [
    "pca->300 dimentions->2 dimention\n",
    "the similar items are will be close in 2d like mango and apples are near(less distance ) because of the they are fruits(similaryity)\n",
    "\n",
    "### cosine similarity-> recommandation system.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23752b90",
   "metadata": {},
   "source": [
    "\n",
    "                        -------------------------\n",
    "                        |                       |\n",
    "                        |                       |\n",
    "encoded words---------->|        EMBEDDING      |-----> word embeddings.\n",
    "                        |        LAYER          |\n",
    "                        |                       |\n",
    "                        -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa206dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## word Embedding Representation.\n",
    "from tensorflow.keras.layers  import Embedding\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf0699",
   "metadata": {},
   "source": [
    "There we have different length of sentence but for training purpose we have to make all the sentences into same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a052b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 8275 8122 2833 6354]\n",
      " [   0    0    0    0 8275 8122 2833 1983]\n",
      " [   0    0    0    0 8275 6656 2833 8193]\n",
      " [   0    0    0 1457 8808 3496 7470 7507]\n",
      " [   0    0    0 8789 8275 7286 2833 2067]\n",
      " [   0    0    0    0 8120  591 1297 7470]]\n"
     ]
    }
   ],
   "source": [
    "sent_length = 8\n",
    "embedding_doc = pad_sequences(one_hot_repre,maxlen=sent_length,padding='pre')\n",
    "print(embedding_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b1c42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature representation\n",
    "dim = 10\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=voc_size,output_dim=dim))\n",
    "model.build(input_shape=(None,sent_length))\n",
    "model.compile(\"adam\",\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5a03f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m10\u001b[0m)          │       \u001b[38;5;34m100,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> (390.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,000\u001b[0m (390.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> (390.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,000\u001b[0m (390.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87c27daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x779a842fa980> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [ 0.01969541, -0.00040132, -0.00856922, -0.04914551,\n",
       "         -0.04435417,  0.01089232, -0.0404256 , -0.00583724,\n",
       "         -0.04726133, -0.01400479],\n",
       "        [-0.03286408,  0.03437345, -0.03776078, -0.03439265,\n",
       "          0.04092412, -0.0466346 ,  0.03091848,  0.00741883,\n",
       "         -0.01240388, -0.02635911],\n",
       "        [ 0.02290009, -0.00029739, -0.01346882,  0.04646805,\n",
       "          0.01743892,  0.04342103, -0.01376774, -0.00631984,\n",
       "         -0.01479862, -0.03234075],\n",
       "        [ 0.01425301,  0.0147993 , -0.00793059,  0.01705699,\n",
       "         -0.03886753, -0.0426972 ,  0.04769541,  0.0072795 ,\n",
       "         -0.02979971,  0.00527003]],\n",
       "\n",
       "       [[-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [ 0.01969541, -0.00040132, -0.00856922, -0.04914551,\n",
       "         -0.04435417,  0.01089232, -0.0404256 , -0.00583724,\n",
       "         -0.04726133, -0.01400479],\n",
       "        [-0.03286408,  0.03437345, -0.03776078, -0.03439265,\n",
       "          0.04092412, -0.0466346 ,  0.03091848,  0.00741883,\n",
       "         -0.01240388, -0.02635911],\n",
       "        [ 0.02290009, -0.00029739, -0.01346882,  0.04646805,\n",
       "          0.01743892,  0.04342103, -0.01376774, -0.00631984,\n",
       "         -0.01479862, -0.03234075],\n",
       "        [ 0.01377494,  0.04075046, -0.03223683,  0.01568173,\n",
       "         -0.02226599,  0.03499467, -0.01735418, -0.00143148,\n",
       "          0.01074773,  0.00598663]],\n",
       "\n",
       "       [[-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [ 0.01969541, -0.00040132, -0.00856922, -0.04914551,\n",
       "         -0.04435417,  0.01089232, -0.0404256 , -0.00583724,\n",
       "         -0.04726133, -0.01400479],\n",
       "        [-0.01812953, -0.01078303,  0.02781076, -0.02153443,\n",
       "          0.02565136,  0.02401482,  0.01763378, -0.04359486,\n",
       "          0.04916478,  0.00604143],\n",
       "        [ 0.02290009, -0.00029739, -0.01346882,  0.04646805,\n",
       "          0.01743892,  0.04342103, -0.01376774, -0.00631984,\n",
       "         -0.01479862, -0.03234075],\n",
       "        [ 0.01284311,  0.01209111, -0.02081524, -0.00676919,\n",
       "          0.00293163, -0.01289   ,  0.00370331,  0.0132768 ,\n",
       "         -0.00808029, -0.04410538]],\n",
       "\n",
       "       [[-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.03755664,  0.03033955,  0.03828939,  0.0145165 ,\n",
       "         -0.04748985, -0.03753333, -0.00313725, -0.02190799,\n",
       "         -0.00878166,  0.04333897],\n",
       "        [ 0.01296523,  0.00172465,  0.03332483,  0.04751848,\n",
       "         -0.00120128, -0.02281602, -0.04752158, -0.0358039 ,\n",
       "         -0.04516182,  0.03044901],\n",
       "        [ 0.00130981, -0.02384301,  0.00488981, -0.04356296,\n",
       "          0.03352718,  0.04153589,  0.0231351 ,  0.01907816,\n",
       "         -0.00525265,  0.01876305],\n",
       "        [ 0.0022853 ,  0.02373961,  0.01671983, -0.03591802,\n",
       "         -0.02763492, -0.00686246, -0.02195051,  0.02586975,\n",
       "         -0.00395393, -0.03601946],\n",
       "        [ 0.04268244, -0.04160366, -0.03977505,  0.04078713,\n",
       "         -0.00822871,  0.01911372,  0.00124438, -0.03645394,\n",
       "         -0.03624957,  0.02102714]],\n",
       "\n",
       "       [[-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.02266669,  0.02942567, -0.03318857,  0.0305973 ,\n",
       "          0.04745133,  0.04216046,  0.04585161,  0.02993213,\n",
       "          0.02601441, -0.01357664],\n",
       "        [ 0.01969541, -0.00040132, -0.00856922, -0.04914551,\n",
       "         -0.04435417,  0.01089232, -0.0404256 , -0.00583724,\n",
       "         -0.04726133, -0.01400479],\n",
       "        [ 0.01769676,  0.01125408, -0.00718492,  0.01355991,\n",
       "          0.00293944, -0.03669165, -0.03531549, -0.04256914,\n",
       "         -0.01686943, -0.04504425],\n",
       "        [ 0.02290009, -0.00029739, -0.01346882,  0.04646805,\n",
       "          0.01743892,  0.04342103, -0.01376774, -0.00631984,\n",
       "         -0.01479862, -0.03234075],\n",
       "        [-0.00796191,  0.02530983, -0.04700724,  0.03354112,\n",
       "          0.00743368, -0.03049274,  0.00526048, -0.01335449,\n",
       "          0.0088992 , -0.04898132]],\n",
       "\n",
       "       [[-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.02463952,  0.00216218, -0.03274222, -0.04523081,\n",
       "         -0.01174098,  0.01562187, -0.02380737, -0.04992985,\n",
       "         -0.01999047,  0.00960785],\n",
       "        [-0.04014825, -0.01130186,  0.01314146, -0.00311659,\n",
       "         -0.01871618,  0.01809163,  0.03952448, -0.04274857,\n",
       "         -0.03530138,  0.03763403],\n",
       "        [-0.03570952, -0.01617321, -0.01341937,  0.04053123,\n",
       "          0.01278036,  0.01672499, -0.03218596, -0.04201669,\n",
       "         -0.02002805,  0.02038145],\n",
       "        [ 0.0022853 ,  0.02373961,  0.01671983, -0.03591802,\n",
       "         -0.02763492, -0.00686246, -0.02195051,  0.02586975,\n",
       "         -0.00395393, -0.03601946]]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedding_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bbe5c3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), array([   0,    0,    0,    0, 8275, 8122, 2833, 6354], dtype=int32))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_doc[0].shape,embedding_doc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b22ebd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [-0.01941752, -0.03830229, -0.01822414, -0.04492264,\n",
       "         -0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,\n",
       "          0.02516187, -0.02406915],\n",
       "        [ 0.01969541, -0.00040132, -0.00856922, -0.04914551,\n",
       "         -0.04435417,  0.01089232, -0.0404256 , -0.00583724,\n",
       "         -0.04726133, -0.01400479],\n",
       "        [-0.03286408,  0.03437345, -0.03776078, -0.03439265,\n",
       "          0.04092412, -0.0466346 ,  0.03091848,  0.00741883,\n",
       "         -0.01240388, -0.02635911],\n",
       "        [ 0.02290009, -0.00029739, -0.01346882,  0.04646805,\n",
       "          0.01743892,  0.04342103, -0.01376774, -0.00631984,\n",
       "         -0.01479862, -0.03234075],\n",
       "        [ 0.01425301,  0.0147993 , -0.00793059,  0.01705699,\n",
       "         -0.03886753, -0.0426972 ,  0.04769541,  0.0072795 ,\n",
       "         -0.02979971,  0.00527003]]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([embedding_doc[0]]))  ## just converted to 2d array because the embedding_doc[0] is 1d // or another method is np.reshape(embdding_doc[0],(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930ec59",
   "metadata": {},
   "source": [
    "### Here the 0->[-0.01941752, -0.03830229, -0.01822414, -0.04492264,-0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,0.02516187,-0.02406915]\n",
    "\n",
    "### 8275->[-0.01941752, -0.03830229, -0.01822414, -0.04492264,-0.0262815 ,  0.0274807 , -0.02941034, -0.02100879,0.02516187, -0.02406915]    etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
